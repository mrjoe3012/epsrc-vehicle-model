{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Any\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm as tqdm\n",
    "from ray import tune\n",
    "from ray.air import Checkpoint, session\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from numpy.typing import NDArray\n",
    "from lib import *\n",
    "import torch, os, pickle, time, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_device(\"cuda:0\")\n",
    "with open(\"constraints.p\", \"rb\") as f:\n",
    "    (input_constraints, output_constraints) = pickle.load(f)\n",
    "    input_constraints = InputConstraints(input_constraints.means, input_constraints.stds)\n",
    "    output_constraints = OutputConstraints(output_constraints.means, output_constraints.stds)\n",
    "train_dataset = SimData(\"./train.bin\", in_memory=True)\n",
    "test_dataset = SimData(\"./test.bin\", in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "###################\n",
    "# Train/Test Loop #\n",
    "###################\n",
    "\n",
    "def train_test_loop(\n",
    "        epochs = 500, k = 5, batch_size = 4096,\n",
    "        num_layers = 2, num_neurons = 256, learning_rate = 6e-3,\n",
    "        verbose = False, filename = None, save_files = True, show_plots = False):\n",
    "    n = epochs // k\n",
    "    # 'filename' : to load a pre-trained model\n",
    "    # 'k' : for validation loss plots\n",
    "\n",
    "\n",
    "    config_dict = {\n",
    "        'epochs' : epochs,\n",
    "        'k' : k,\n",
    "        'batch_size' : batch_size,\n",
    "        'num_layers' : num_layers,\n",
    "        'num_neurons' : num_neurons,\n",
    "        'learning_rate' : learning_rate,\n",
    "        'verbose' : verbose,\n",
    "        'filename' : filename,\n",
    "        'save_files' : save_files,\n",
    "        'show_plots' : show_plots\n",
    "    }\n",
    "\n",
    "    # timestamp at start of training\n",
    "    timestr = time.strftime(\"%d-%m-%Y-%H:%M:%S\")\n",
    "    output_directory = Path(\"./\") / f\"training-{timestr}\"\n",
    "    if save_files:\n",
    "        os.mkdir(output_directory)\n",
    "        os.mkdir(output_directory / \"train\")\n",
    "        os.mkdir(output_directory / \"test\")\n",
    "\n",
    "    # construct or load the model\n",
    "    if filename is None:\n",
    "        model = VehicleModel(\n",
    "            input_constraints,\n",
    "            output_constraints,\n",
    "            num_neurons,\n",
    "            num_layers,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    else:\n",
    "        model = torch.load(filename)\n",
    "\n",
    "    # initialise the optimiser\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr = learning_rate    \n",
    "    )\n",
    "\n",
    "    # train the model\n",
    "    training_loss = []\n",
    "    validation_loss = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i in tqdm(range(n), \"Training\", disable=False):\n",
    "        training_loss += model.train_loop(\n",
    "            train_dataset,\n",
    "            batch_size,\n",
    "            k,\n",
    "            optimizer\n",
    "        )\n",
    "        vl = model.test_loop(\n",
    "            test_dataset,\n",
    "            batch_size\n",
    "        )\n",
    "        validation_loss += [vl]\n",
    "\n",
    "    print(f\"Final Validation Loss: {validation_loss[-1]}\")\n",
    "    print(f\"Final Training Loss: {training_loss[-1]}\")\n",
    "    plt.plot(\n",
    "        list(range(1, epochs + 1, 1)),\n",
    "        training_loss,\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    plt.plot(\n",
    "        list(range(k, epochs + 1, k)),\n",
    "        validation_loss,\n",
    "        color=\"red\"\n",
    "    )\n",
    "    plt.yscale(\"log\")\n",
    "    if save_files:\n",
    "        plt.savefig(output_directory / \"loss.png\")\n",
    "        torch.save(model, output_directory / \"model.pt\")\n",
    "        with open(output_directory / \"meta.json\", \"w\") as f: json.dump(config_dict, f, indent=1)\n",
    "    if show_plots == True:\n",
    "        plt.show()\n",
    "    model.plot_predictions(\n",
    "        train_dataset,\n",
    "        output_directory / \"train\" if save_files else None,\n",
    "        show = show_plots\n",
    "    )\n",
    "    model.plot_predictions(\n",
    "        test_dataset,\n",
    "        output_directory / \"test\" if save_files else None,\n",
    "        show = show_plots\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 1/1000 [00:25<7:12:21, 25.97s/it]"
     ]
    }
   ],
   "source": [
    "train_test_loop(\n",
    "    epochs = 5000,\n",
    "    k = 5,\n",
    "    batch_size = 4096,\n",
    "    num_layers = 2,\n",
    "    num_neurons = 256,\n",
    "    learning_rate = 6e-3,\n",
    "    verbose = False,\n",
    "    save_files = True,\n",
    "    show_plots = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 07:21:33,100\tWARNING services.py:1832 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=8.50gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2023-08-15 07:21:34,350\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2023-08-15 07:21:35,037\tINFO tune.py:226 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2023-08-15 07:21:35,039\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2023-08-15 07:21:35,040\tWARNING syncer.py:260 -- You are using remote storage, but you don't have `fsspec` installed. This can lead to inefficient syncing behavior. To avoid this, install fsspec with `pip install fsspec`. Depending on your remote storage provider, consider installing the respective fsspec-package (see https://github.com/fsspec).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-08-15 07:24:41</td></tr>\n",
       "<tr><td>Running for: </td><td>00:03:06.32        </td></tr>\n",
       "<tr><td>Memory:      </td><td>97.3/503.3 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Logical resource usage: 1.0/3 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:TITAN)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc             </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_layers</th><th style=\"text-align: right;\">  num_neurons</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_5daa1_00000</td><td>RUNNING </td><td>10.129.0.171:422</td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">2.8464e-05 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">         4096</td></tr>\n",
       "<tr><td>train_5daa1_00001</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.0015949  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          128</td></tr>\n",
       "<tr><td>train_5daa1_00002</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.000810846</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">         2048</td></tr>\n",
       "<tr><td>train_5daa1_00003</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.000248641</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         2048</td></tr>\n",
       "<tr><td>train_5daa1_00004</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.00120552 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          128</td></tr>\n",
       "<tr><td>train_5daa1_00005</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">1.46102e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">          512</td></tr>\n",
       "<tr><td>train_5daa1_00006</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.00014993 </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">          512</td></tr>\n",
       "<tr><td>train_5daa1_00007</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">9.74832e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">          512</td></tr>\n",
       "<tr><td>train_5daa1_00008</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.0118121  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          128</td></tr>\n",
       "<tr><td>train_5daa1_00009</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">9.31523e-05</td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">         4096</td></tr>\n",
       "<tr><td>train_5daa1_00010</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.00073804 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         2048</td></tr>\n",
       "<tr><td>train_5daa1_00011</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.0232616  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           32</td></tr>\n",
       "<tr><td>train_5daa1_00012</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.0381875  </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">           16</td></tr>\n",
       "<tr><td>train_5daa1_00013</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.00989313 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          128</td></tr>\n",
       "<tr><td>train_5daa1_00014</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.00589125 </td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">          128</td></tr>\n",
       "<tr><td>train_5daa1_00015</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">4.76787e-05</td><td style=\"text-align: right;\">           2</td><td style=\"text-align: right;\">         4096</td></tr>\n",
       "<tr><td>train_5daa1_00016</td><td>PENDING </td><td>                </td><td style=\"text-align: right;\">        4096</td><td style=\"text-align: right;\">0.0200049  </td><td style=\"text-align: right;\">           1</td><td style=\"text-align: right;\">         1024</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "########################\n",
    "# Parameter Experiment #\n",
    "########################\n",
    "\n",
    "def train(config):\n",
    "    torch.set_default_device(\"cuda:0\")\n",
    "    train_dataset = SimData(\"/nfs/vehicle-model/train.bin\", in_memory=True)\n",
    "    test_dataset = SimData(\"/nfs/vehicle-model/test.bin\", in_memory=True)\n",
    "\n",
    "    epochs = 1000\n",
    "    model = VehicleModel(\n",
    "        input_constraints,\n",
    "        output_constraints,\n",
    "        config[\"num_neurons\"],\n",
    "        config[\"num_layers\"],\n",
    "        False\n",
    "    )\n",
    "    model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr = config[\"lr\"]\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    train_err = model.train_loop(\n",
    "        train_dataset,\n",
    "        config[\"batch_size\"],\n",
    "        epochs,\n",
    "        optimizer\n",
    "    )\n",
    "\n",
    "    test_err = model.test_loop(\n",
    "        test_dataset,\n",
    "        config[\"batch_size\"]\n",
    "    )\n",
    "\n",
    "    session.report({\n",
    "        \"final_test_rmse\" : test_err,\n",
    "        \"final_train_rmse\" : train_err[-1],\n",
    "        \"train_rmse\" : train_err\n",
    "    })\n",
    "\n",
    "config = {\n",
    "    \"num_layers\" : tune.choice([1, 2]),\n",
    "    \"num_neurons\" : tune.choice(2**i for i in range(4, 13)),\n",
    "    \"lr\" : tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\" : tune.choice([4096])\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"final_train_rmse\",\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "result = tune.run(\n",
    "    train,\n",
    "    config=config,\n",
    "    scheduler=scheduler,\n",
    "    num_samples=20,\n",
    "    resources_per_trial={'cpu' : 1, 'gpu' : 1}\n",
    ")\n",
    "\n",
    "pickle.dump(result.dataframe(), open(f\"parameter-experiment-{time.strftime('%d-%m-%Y-%H:%M:%S')}.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "k = 5\n",
    "batch_size = 4096\n",
    "verbose = False\n",
    "save_files = True\n",
    "filename = None\n",
    "show_plots = False\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        'epochs' : epochs,\n",
    "        'k' : k,\n",
    "        'batch_size' : batch_size,\n",
    "        'num_layers' : 3,\n",
    "        'num_neurons' : 128,\n",
    "        'learning_rate' : 1.2e-3,\n",
    "        'verbose' : False,\n",
    "        'filename' : filename,\n",
    "        'save_files' : save_files\n",
    "    },\n",
    "    {\n",
    "        'epochs' : epochs,\n",
    "        'k' : k,\n",
    "        'batch_size' : batch_size,\n",
    "        'num_layers' : 3,\n",
    "        'num_neurons' : 256,\n",
    "        'learning_rate' : 1.5e-3,\n",
    "        'verbose' : False,\n",
    "        'filename' : filename,\n",
    "        'save_files' : save_files\n",
    "    },\n",
    "    {\n",
    "        'epochs' : epochs,\n",
    "        'k' : k,\n",
    "        'batch_size' : batch_size,\n",
    "        'num_layers' : 3,\n",
    "        'num_neurons' : 256,\n",
    "        'learning_rate' : 2.9e-3,\n",
    "        'verbose' : False,\n",
    "        'filename' : filename,\n",
    "        'save_files' : save_files\n",
    "    },\n",
    "    {\n",
    "        'epochs' : epochs,\n",
    "        'k' : k,\n",
    "        'batch_size' : batch_size,\n",
    "        'num_layers' : 1,\n",
    "        'num_neurons' : 512,\n",
    "        'learning_rate' : 1e-2,\n",
    "        'verbose' : False,\n",
    "        'filename' : filename,\n",
    "        'save_files' : save_files\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_params in models:\n",
    "    train_test_loop(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "result.dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
